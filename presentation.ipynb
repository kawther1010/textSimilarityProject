{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. IMPORT AND INSTALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/kawther/.local/lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/kawther/.local/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/kawther/.local/lib/python3.8/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/kawther/.local/lib/python3.8/site-packages (from scikit-learn) (1.23.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/kawther/.local/lib/python3.8/site-packages (from scikit-learn) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. DEFINING DEFAULT FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filePath):\n",
    "    with open(filePath, 'r') as fichier:\n",
    "        text = fichier.read()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1= readFile('data/text1.txt')\n",
    "text2= readFile('data/text2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<2x57 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 71 stored elements in Compressed Sparse Row format>,\n",
       " array(['ability', 'algorithms', 'and', 'artificial', 'automatically',\n",
       "        'being', 'between', 'computational', 'computers', 'development',\n",
       "        'enable', 'experience', 'explicit', 'explicitly', 'field',\n",
       "        'focuses', 'from', 'generate', 'human', 'humans', 'improve',\n",
       "        'inference', 'instead', 'instructions', 'intelligence',\n",
       "        'interaction', 'interpret', 'involves', 'is', 'it', 'language',\n",
       "        'learn', 'learning', 'like', 'machine', 'models', 'natural', 'nlp',\n",
       "        'of', 'on', 'patterns', 'perform', 'processing', 'programmed',\n",
       "        'provides', 'relying', 'statistical', 'subset', 'systems', 'tasks',\n",
       "        'that', 'the', 'to', 'understand', 'use', 'using', 'without'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorization(text1, text2):\n",
    "    vectorizer = CountVectorizer()\n",
    "    count_matrix = vectorizer.fit_transform([text1, text2])\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    return count_matrix, feature_names\n",
    "\n",
    "vectorization(text1, text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix, feature_names= vectorization(text1, text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. COSIN SIMILARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosin_sim(count_matrix):\n",
    "    cosine_sim = cosine_similarity(count_matrix[0], count_matrix[1])\n",
    "    return cosine_sim[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4972451580988469"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosin_sim(count_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. SIMILARITY EUCLIDEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts1 = count_matrix.toarray()[0]\n",
    "word_counts2 = count_matrix.toarray()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word frequencies in word_count1:\n",
      "ability: 0\n",
      "algorithms: 1\n",
      "and: 3\n",
      "artificial: 1\n",
      "automatically: 0\n",
      "being: 0\n",
      "between: 1\n",
      "computational: 1\n",
      "computers: 1\n",
      "development: 1\n",
      "enable: 0\n",
      "experience: 0\n",
      "explicit: 0\n",
      "explicitly: 0\n",
      "field: 1\n",
      "focuses: 1\n",
      "from: 0\n",
      "generate: 1\n",
      "human: 1\n",
      "humans: 1\n",
      "improve: 0\n",
      "inference: 0\n",
      "instead: 0\n",
      "instructions: 0\n",
      "intelligence: 1\n",
      "interaction: 1\n",
      "interpret: 1\n",
      "involves: 1\n",
      "is: 1\n",
      "it: 1\n",
      "language: 3\n",
      "learn: 0\n",
      "learning: 0\n",
      "like: 1\n",
      "machine: 0\n",
      "models: 1\n",
      "natural: 2\n",
      "nlp: 1\n",
      "of: 2\n",
      "on: 1\n",
      "patterns: 0\n",
      "perform: 0\n",
      "processing: 1\n",
      "programmed: 0\n",
      "provides: 0\n",
      "relying: 0\n",
      "statistical: 0\n",
      "subset: 0\n",
      "systems: 0\n",
      "tasks: 0\n",
      "that: 1\n",
      "the: 2\n",
      "to: 1\n",
      "understand: 1\n",
      "use: 0\n",
      "using: 1\n",
      "without: 0\n",
      "\n",
      "Word frequencies in word_count2:\n",
      "ability: 1\n",
      "algorithms: 1\n",
      "and: 3\n",
      "artificial: 1\n",
      "automatically: 1\n",
      "being: 1\n",
      "between: 0\n",
      "computational: 0\n",
      "computers: 1\n",
      "development: 0\n",
      "enable: 1\n",
      "experience: 1\n",
      "explicit: 1\n",
      "explicitly: 1\n",
      "field: 0\n",
      "focuses: 0\n",
      "from: 1\n",
      "generate: 0\n",
      "human: 0\n",
      "humans: 0\n",
      "improve: 1\n",
      "inference: 1\n",
      "instead: 1\n",
      "instructions: 1\n",
      "intelligence: 1\n",
      "interaction: 0\n",
      "interpret: 0\n",
      "involves: 1\n",
      "is: 1\n",
      "it: 1\n",
      "language: 0\n",
      "learn: 1\n",
      "learning: 1\n",
      "like: 0\n",
      "machine: 1\n",
      "models: 1\n",
      "natural: 0\n",
      "nlp: 0\n",
      "of: 2\n",
      "on: 1\n",
      "patterns: 1\n",
      "perform: 1\n",
      "processing: 0\n",
      "programmed: 1\n",
      "provides: 1\n",
      "relying: 1\n",
      "statistical: 1\n",
      "subset: 1\n",
      "systems: 1\n",
      "tasks: 1\n",
      "that: 1\n",
      "the: 2\n",
      "to: 3\n",
      "understand: 0\n",
      "use: 1\n",
      "using: 0\n",
      "without: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Word frequencies in word_count1:\")\n",
    "for i in range(len(feature_names)):\n",
    "    print(f\"{feature_names[i]}: {word_counts1[i]}\")\n",
    "\n",
    "\n",
    "print(\"\\nWord frequencies in word_count2:\")\n",
    "for i in range(len(feature_names)):\n",
    "    print(f\"{feature_names[i]}: {word_counts2[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenCount(list):\n",
    "    n= len(list)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.810249675906654"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sim_euclidean(x, y):\n",
    "    sim=0\n",
    "    n= lenCount(feature_names)\n",
    "    for i in range (n):\n",
    "        sim= sim+ (x[i]-y[i])**2\n",
    "    \n",
    "    sim= math.sqrt(sim)\n",
    "    return sim\n",
    "\n",
    "sim_euclidean(word_counts1, word_counts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude(word_counts):\n",
    "    magnitude = math.sqrt(sum(x**2 for x in word_counts))\n",
    "    return magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 3, 0, 0, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magnitude1 = 7.483314773547883\n",
      "Magnitude2 = 8.06225774829855\n"
     ]
    }
   ],
   "source": [
    "magnitude1 = magnitude(word_counts1)\n",
    "magnitude2 = magnitude(word_counts2)\n",
    "\n",
    "print(\"Magnitude1 =\", magnitude1)\n",
    "print(\"Magnitude2 =\", magnitude2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(word_counts1, word_counts2, magnitude1, magnitude2):\n",
    "    norm=sim_euclidean(word_counts1, word_counts2)/(magnitude1*magnitude2)\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12945362782958908"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalization(word_counts1, word_counts2, magnitude1, magnitude2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idfCosin(text1, text2):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform([text1, text2])\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
    "    return cosine_sim[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34030588268029877"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idfCosin(text1, text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idfEuclidean(text1, text2):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform([text1, text2])\n",
    "    euclidean_distance = pairwise_distances(tfidf_matrix, metric=\"euclidean\")\n",
    "    return euclidean_distance[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1486462617531137"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idfEuclidean(text1,text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idfEuc= tf_idfEuclidean(text1,text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. FINAL RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4972451580988469"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosin_sim(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12945362782958908"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalization(word_counts1, word_counts2, magnitude1, magnitude2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34030588268029877"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idfCosin(text1, text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1486462617531137"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idfEuclidean(text1,text2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
